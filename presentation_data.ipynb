{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gather original df\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#get plots to show up in jn\n",
    "%matplotlib inline\n",
    "#get plots to be an svg when exporting\n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(week_nums):\n",
    "    url = \"http://web.mta.info/developers/data/nyct/turnstile/turnstile_{}.txt\"\n",
    "    dfs = []\n",
    "    for week_num in week_nums:\n",
    "        file_url = url.format(week_num)\n",
    "        dfs.append(pd.read_csv(file_url))\n",
    "    return pd.concat(dfs)\n",
    "        \n",
    "week_nums = [180407, 180414, 180421, 180428, 180505, 180512, 180519, 180526, 180602, 180609, 180616, 180623]\n",
    "data = get_data(week_nums)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cleaning up data\n",
    "\n",
    "df = data.copy()\n",
    "\n",
    "df.columns = [column.strip() for column in df.columns]\n",
    "\n",
    "df['STATION'].apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get datetime column\n",
    "df[\"DATE_TIME\"] = pd.to_datetime(df.DATE + \" \" + df.TIME, format=\"%m/%d/%Y %H:%M:%S\")\n",
    "\n",
    "#drop dupes\n",
    "\n",
    "df.sort_values([\"C/A\", \"UNIT\", \"SCP\", \"STATION\", \"DATE_TIME\"], inplace=True, ascending=False)\n",
    "\n",
    "df.drop_duplicates(subset=[\"C/A\", \"UNIT\", \"SCP\", \"STATION\", \"DATE_TIME\"], inplace=True)\n",
    "\n",
    "df = df.drop([\"EXITS\", \"DESC\"], axis=1, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sort so prev entries will work\n",
    "(df\n",
    " .groupby([\"C/A\", \"UNIT\", \"SCP\", \"STATION\", \"DATE_TIME\"])\n",
    " .ENTRIES.count()\n",
    " .reset_index()\n",
    " .sort_values(\"ENTRIES\", ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#put in prev entries column\n",
    "df_daily = df.groupby([\"C/A\", \"UNIT\", \"SCP\", \"STATION\", \"DATE\"])\\\n",
    ".ENTRIES.first().reset_index().copy()\n",
    "\n",
    "df_daily[[\"PREV_DATE\", \"PREV_ENTRIES\"]] = (df_daily.groupby([\"C/A\", \"UNIT\", \"SCP\", \"STATION\"])[\"DATE\", \"ENTRIES\"].transform(lambda grp: grp.shift(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix daily counts\n",
    "\n",
    "def get_daily_counts(row, max_counter):\n",
    "    counter = row[\"ENTRIES\"] - row[\"PREV_ENTRIES\"]\n",
    "    if counter < 0:\n",
    "        # Maybe counter is reversed?\n",
    "        counter = -counter\n",
    "    if counter > max_counter:\n",
    "        #print(row[\"ENTRIES\"], row[\"PREV_ENTRIES\"])\n",
    "        counter = min(row[\"ENTRIES\"], row[\"PREV_ENTRIES\"])\n",
    "        # if current entries is bad, use yesterday's count as proxy\n",
    "    if counter > max_counter:\n",
    "        # Check it again to make sure we are not giving a counter that's too big\n",
    "        return 0\n",
    "    return counter\n",
    "\n",
    "df_daily.apply(get_daily_counts, axis=1, max_counter=1000000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subtract prev values to make daily entries column\n",
    "df_daily[\"DAILY_ENTRIES\"] = df_daily.apply(get_daily_counts, axis=1, max_counter=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_daily_sta = df_daily.groupby(['STATION', 'DATE'])['DAILY_ENTRIES'].sum().reset_index().sort_values('DATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = df_daily_sta.DATE\n",
    "\n",
    "riders = df_daily_sta.DAILY_ENTRIES\n",
    "\n",
    "plt.figure(figsize =(12,6))\n",
    "plt.plot(dates, riders)\n",
    "plt.xticks(rotation = 'vertical');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily_sta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
